## 总结
- 本周主要学习内容：
    - 复杂度概念
    - 数组
    - 链表
- 由于每天的时间有限，但是每天都有坚持习题练习
- 每周的学习任务
    - 刷题狂魔群，每日一题
    - 勤学好问群，每周完成一篇学习心得
    - 每天算法学习打卡，写每天的学习笔记
    - 每周刷学习视频
    - 从覃超老师布置的题目中，至少完成并提交 2 道
    - 每周完成学习心得，提交到gitHub
    - 每周需要 review 并点评至少 5 位同学的代码作业或学习总结
 - 本周对复杂度概念，数组，链表的笔记整理，如下  

## 1. 复杂度

这里面有 10 个数据结构：
  ● 数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；
10 个算法：
  ● 递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。
一、时间复杂度分析
1. 只关注循环执行次数最多的一段代码
所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。
T(n)=O(f(n))
大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

2. 加法法则：总复杂度等于量级最大的那段代码的复杂度
T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).

3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积
如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)).
假设 T1(n) = O(n)，T2(n) = O(n2次方)，则 T1(n) * T2(n) = O(n3次方)

几种常见时间复杂度实例分析
- 多项式量级 非多项式量级
- 常量阶 O(1) 指数阶 2n次方
- 对数阶 O(log n) 阶乘阶 n！
- 线性阶 O(n) 
- 线性对数阶 O(nlog n) 
- 平方阶 O(n2次方),立方阶 O(n3次方),... 

把时间复杂度为非多项式量级的算法问题叫做NP（Non-Deterministic Polynomial,非确定多项式）问题，当数据规模n越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无线增长。
所以，非多项式时间复杂度的算法其实是非常低效的算法。

多项式量级的排序：
常量阶 O(1) < 对数阶 O(log n) < 线性阶 O(n) < 线性对数阶 O(n log n) < 平方阶 O(n2次方) < 立方阶


1. O(1)
 int i = 8;
 int j = 6;
 int sum = i + j;
2. O(logn)、O(nlogn)
 i=1;
 while (i <= n)  {
   i = i * 2;
 }
3. O(m+n)、O(m*n)
O(m+n) = m + n;
O(m*n) = m + n;
大 O 表示法和时间复杂度分析
二、空间复杂度分析
时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。
空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。

void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }
  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}

我们常见的空间复杂度就是 O(1)、O(n)、O(n2)，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。

  ● 最好情况时间复杂度（best case time complexity）、
  ● 最坏情况时间复杂度（worst case time complexity）、
  ● 平均情况时间复杂度（average case time complexity）、
  ● 均摊时间复杂度（amortized time complexity）

均摊时间复杂度就是一种特殊的平均时间复杂度


1. 最好情况时间复杂度为 O(1)
2.最坏情况分析：
最坏情况代码执行的次数跟每次数组的长度有关
第1次调用insert的执行的次数为 n ,
第2次调用insert的执行的次数为 2n ,
第3次调用insert的执行的次数为 2^2 * n
第k次调用insert的执行的次数为 2^(k-1) * n
最坏时间复杂度为 O(n)。
3. 平均情况分析
当每次遇到最坏情况时数组会进行2倍扩容，原数组被导入新数组，虽然数组的长度变大了，但是插入操作落在的区间的长度是一样的，分别是0~len-1, len~(2len-1),....；
插入的情况仍是len+1种：0~len-1和插满之后的O(len)；所以每次插入的概率是：p= 1/len+1，
最后求出加权平均时间复杂度为 1*p + 2*p+ ▪▪▪ + len*p + len * p = O(1) ;
4. 均摊时间复杂度 O(1)
而均摊复杂度由于每次O(len)的出现都跟着len次O(1)，是前后连贯的，因而将O(len)平摊到前len次上，得出平摊复杂度是O(1)





## 2. 数组
数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。
1. 数组的两个特性：
(1) 线性表（Linear List）：数组，链表、队列、栈等也是线性表结构。
非线性表：二叉树、堆、图
(2) 第二个是连续的内存空间和相同类型的数据。
2. 数组寻址
a[i]_address = base_address + i * data_type_size
int[] a = new int[10];
10个长度的int类型的数组，每个元素是int类型，int类型是4个字节， 4 * 8 = 32 bit
给这个数组分配内存地址，首地址是1000，1000 + 10 * 4 - 1= 1039
a[i]_address = base_address + i * data_type_size
a[0]_address = 1000 + 0 * 4 = 1000 ~ 1003
a[1]_address = 1000 + 1 * 4 = 1004 ~ 1007

3.  链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)。
数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。
  ● 即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。
  ● 正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。

4. 在数组中插入或者删除数据
最好复杂度O(1)
最坏复杂度O(n)
平均复杂度是O(n)
- 快排的思想，在数组中的k位置插入数据，k位置本身的数据移到最后一位，复杂度O(1)

5. 数组和容器
  ● ArrayList 最大的优势就是可以将很多数组操作的细节封装起来
  ● 支持动态扩容。
  ● 每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小
  ● 因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，new ArrayList(10000)代表的是10000 条数据放入 ArrayList
  ● ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类
 tip: 如何选择数组和容器
  ● 特别关注性能，或者希望使用基本类型，就可以选用数组。
  ● 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。
  ● 当要表示多维数组时，用数组往往会更加直观 Object[][] array；容器：ArrayList > array
  ● 在平时的业务开发中，我们可以直接使用编程语言提供的容器类，
  ● 但是，如果是特别底层的开发，直接使用数组可能会更合适。

6. 为什么数组是从0开始
a[k]_address = base_address + k * type_size
如果从1开始
a[k]_address = base_address + (k-1)*type_size，
每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。

问题：
1. JVM 的标记清除垃圾回收算法的核心理念

2. 二维数组的内存寻址公式是怎样的呢？
对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为：
a [ i ][ j ]address = base_address + ( i * n + j) * type_size
D[i][j]=xD+L(C·i+j)，其中xD为二维数组的首地址，L为数组的元素数据类型的大小，C为定义的行长度。

充电站：
1. bit（比特）是表示信息的最小单位；一个bit只能存是0还是1；
2. 一个Byte由8 bits组成，是数据存储的基础单位，1Byte又称为一个字节，用一个字节（Byte）储存，可区别256个数字。
1Byte = 8bits => 11111111 =>  108 + 64 + 32 + 16 + 8 + 4 + 2 + 1 = 255
3. 一个中文需要两个字节， int类型4个字节
1 Byte = 8 Bits
1 KB = 1024 Bytes
1 MB = 1024 KB
1 GB = 1024 MB

## 3. 链表
1. 缓存是一种提高数据读取性能的技术，
  ● CPU 缓存、
  ● 数据库缓存、
  ● 浏览器缓存
2. 缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留
缓存淘汰策略:
  ● 先进先出策略 FIFO（First In，First Out）、
  ● 最少使用策略 LFU（Least Frequently Used）、
  ● 最近最少使用策略 LRU（Least Recently Used）
3. 数组和链表需要的内存空间
数组需要一块连续的内存空间来存储，对内存的要求比较高。
申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。
链表恰恰相反，它通过“指针”将一组零散的内存块串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。
4. 链表
  ● 单链表

  ● 双向链表

  ● 循环链表

（1）结点
内存块称为链表的“结点”
结点的作用： 存储数据，记录下一个结点的地址
（2）指针
后续指针：结点记录下个结点地址的指针叫作后继指针 next
头结点：第一个结点叫作头结点，头结点用来记录链表的基地址
尾结点：最后一个结点叫作尾结点，指针不是指向下一个结点，而是指向一个空地址 NULL
（3） 链表的删除和插入

链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。

5. 循环链表
单链表的尾结点指针指向空地址，表示这就是最后的结点了
循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合		采用循环链表：比如著名的约瑟夫问题。

6. 双向循环链表
（1）每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点
（2）双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。
（3）如果存储同样多的数据，双向链表要比单链表占用更多的内存空间
（4）虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性
（5）双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效

（6）从链表中删除一个数据
  ● 删除结点中“值等于某个给定值”的结点；
  ● 删除给定指针指向的结点。
      ○ 尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。

      ○ 对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。

但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！

对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。

如果你熟悉 Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。

7.  用空间换时间，时间换空间
当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。
缓存实际上就是利用了空间换时间的设计思想


8. LRU 缓存淘汰算法？
我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。
1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。
2. 如果此数据没有在缓存链表中，又可以分为两种情况：
  ● 如果此时缓存未满，则将此结点直接插入到链表的头部；
  ● 如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。








